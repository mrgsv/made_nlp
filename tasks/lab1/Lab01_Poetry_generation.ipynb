{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 01. Poetry generation\n",
    "\n",
    "Let's try to generate some poetry using RNNs. \n",
    "\n",
    "You have several choices here: \n",
    "\n",
    "* The Shakespeare sonnets, file `sonnets.txt` available in the notebook directory.\n",
    "\n",
    "* Роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина. В предобработанном виде доступен по [ссылке](https://github.com/attatrol/data_sources/blob/master/onegin.txt).\n",
    "\n",
    "* Some other text source, if it will be approved by the course staff.\n",
    "\n",
    "Text generation can be designed in several steps:\n",
    "    \n",
    "1. Data loading.\n",
    "2. Dictionary generation.\n",
    "3. Data preprocessing.\n",
    "4. Model (neural network) training.\n",
    "5. Text generation (model evaluation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "from random import sample\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"dark_background\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading: Shakespeare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shakespeare sonnets are awailable at this [link](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). In addition, they are stored in the same directory as this notebook (`sonnetes.txt`). Simple preprocessing is already done for you in the next cell: all technical info is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('sonnets.txt'):\n",
    "    !wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/master/homeworks_basic/Lab2_DL/sonnets.txt\n",
    "\n",
    "with open('sonnets.txt', 'r') as iofile:\n",
    "    text = iofile.readlines()\n",
    "    \n",
    "TEXT_START = 45\n",
    "TEXT_END = -368\n",
    "text = text[TEXT_START : TEXT_END]\n",
    "assert len(text) == 2616"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
    "\n",
    "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Join all the strings into one and lowercase it\n",
    "# Put result into variable text.\n",
    "\n",
    "# Your great code here\n",
    "text = \"\".join(list(map(lambda x: x.lower(), text)))\n",
    "\n",
    "assert len(text) == 100225, 'Are you sure you have concatenated all the strings?'\n",
    "assert not any([x in set(text) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n",
    "print('OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading: \"Евгений Онегин\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('sonnets.txt'):\n",
    "    !wget https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
    "    \n",
    "with open('onegin.txt', 'r') as iofile:\n",
    "    text = iofile.readlines()\n",
    "    \n",
    "text_p = [x.replace('\\t\\t', '') for x in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
    "\n",
    "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pushkin_by_verse.json', 'r') as iofile:\n",
    "    text_pushkin = json.load(iofile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New School Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./full_songs_by_artist.json', 'r') as iofile:\n",
    "    text_songs = json.load(iofile)\n",
    "# text_songs = \"\".join(list(map(lambda x: x.lower(), text_songs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for val in text_songs.values():\n",
    "    for txt in val.values():\n",
    "        text.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = list(map(lambda x: re.split(r\"(\\n{3})\", x), text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rez_text = []\n",
    "for song in text:\n",
    "    rez_text.extend(list(filter(lambda x: x != \"\", song)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1221"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rez_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text_songs - lyrics from Genius.com featuring these artists from New School: \n",
    "* Eldzhey\n",
    "* LSP\n",
    "* Morgenstern\n",
    "* Oxxxymiron\n",
    "* Slava KPSS\n",
    "* Yanix\n",
    "* Noize MC\n",
    "* GONE.Fludd\n",
    "* Big Baby Tape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So, full text contains Onegin + some russian rappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = text_pushkin + rez_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all the characters, that you've seen in the text, into variable `tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(map(lambda x: re.sub(r\"\\xa0\", \" \", re.sub(r\"\\u2005|\\u205f\", \"\", x.lower())), full_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = sorted(set(\"\".join(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary `token_to_idx = {<char>: <index>}` and dictionary `idx_to_token = {<index>: <char>}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict <index>:<char>\n",
    "# Your great code here\n",
    "token_to_idx = {char: idx for idx, char in enumerate(tokens)}\n",
    "\n",
    "# dict <char>:<index>\n",
    "# Your great code here\n",
    "idx_to_token = {idx: char for char, idx in token_to_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comment: in this task we have only 38 different tokens, so let's use one-hot encoding.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to build and train recurrent neural net which would be able to something similar to Shakespeare's poetry.\n",
    "\n",
    "Let's use vanilla RNN, similar to the one created during the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNNCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Implement the scheme above as torch module\n",
    "    \"\"\"\n",
    "    def __init__(self, num_tokens=len(tokens), embedding_size=16, rnn_num_units=64):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.num_units = rnn_num_units\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
    "        self.rnn_update = nn.Linear(\n",
    "            embedding_size + rnn_num_units,\n",
    "            rnn_num_units\n",
    "        )\n",
    "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        \"\"\"\n",
    "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
    "        We'll call it repeatedly to produce the whole sequence.\n",
    "        \n",
    "        :param x: batch of character ids, containing vector of int64\n",
    "        :param h_prev: previous rnn hidden states, containing matrix [batch, rnn_num_units] of float32\n",
    "        \"\"\"\n",
    "        x_emb = self.embedding(x)\n",
    "        x_and_h = torch.cat([x_emb, h_prev], dim=-1)\n",
    "        h_next = self.rnn_update(x_and_h)\n",
    "        \n",
    "        h_next = torch.tanh(h_next)\n",
    "        \n",
    "        assert h_next.size() == h_prev.size()\n",
    "        \n",
    "        logits = self.rnn_to_logits(h_next) \n",
    "        \n",
    "        return h_next, F.log_softmax(logits, -1)\n",
    "    \n",
    "    def initial_state(self, batch_size):\n",
    "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
    "        return torch.zeros(batch_size, self.num_units, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "KARPATHY_CONSTANT = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(words, batch_size, max_len=None, pad=token_to_idx[' '], dtype='int32', batch_first=True):\n",
    "    \"\"\"Casts a list of words into rnn-digestable matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, words))\n",
    "    words_ix = np.zeros([len(words), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        line_ix = [token_to_idx[c] for c in words[i]]\n",
    "        words_ix[i, :len(line_ix)] = line_ix[:max_len]\n",
    "        \n",
    "    if not batch_first: # convert [batch, time] into [time, batch]\n",
    "        words_ix = np.transpose(words_ix)\n",
    "    if words_ix.shape[0] < batch_size:\n",
    "        words_ix = np.vstack((words_ix, np.ones((batch_size - words_ix.shape[0], max_len)) * pad))\n",
    "    return words_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_loop(char_rnn, batch_ix):\n",
    "    \"\"\"\n",
    "    Computes log P(next_character) for all time-steps in words_ix\n",
    "    :param words_ix: an int32 matrix of shape [batch, time], output of to_matrix(words)\n",
    "    \"\"\"\n",
    "    batch_size, max_length = batch_ix.size()\n",
    "    hid_state = char_rnn.initial_state(batch_size)\n",
    "    logprobs = []\n",
    "\n",
    "    for x_t in batch_ix.transpose(0,1):\n",
    "        hid_state, logp_next = char_rnn(x_t, hid_state) \n",
    "        logprobs.append(logp_next)\n",
    "        \n",
    "    return torch.stack(logprobs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(char_rnn, seed_phrase=' ', max_length=MAX_LENGTH, temperature=1.0):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
    "                        smaller temperature converges to the single most likely output\n",
    "    '''\n",
    "    \n",
    "    x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
    "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n",
    "    hid_state = char_rnn.initial_state(batch_size=1)\n",
    "    \n",
    "    #feed the seed phrase, if any\n",
    "    for i in range(len(seed_phrase) - 1):\n",
    "        hid_state, _ = char_rnn(x_sequence[:, i], hid_state)\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        hid_state, logp_next = char_rnn(x_sequence[:, -1], hid_state)\n",
    "        p_next = F.softmax(logp_next / temperature, dim=-1).data.numpy()[0]\n",
    "        \n",
    "        # sample next token and push it back into x_sequence\n",
    "        next_ix = np.random.choice(num_tokens,p=p_next)\n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_rnn = CharRNNCell(num_tokens=num_tokens, embedding_size=64, rnn_num_units=128)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(char_rnn.parameters(), lr=3e-4)\n",
    "# scheduler = StepLR(opt, step_size=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(text) // BATCH_SIZE + 1) * EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "writer.add_graph(char_rnn, to_matrix(text[0: BATCH_SIZE], BATCH_SIZE, max_len=MAX_LENGTH))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "best_valid_loss = float('inf')\n",
    "for epoch in range(EPOCHS):\n",
    "    train_history = []\n",
    "    char_rnn.train()\n",
    "    for i in range(len(text) // BATCH_SIZE + 1):\n",
    "        batch_ix = to_matrix(text[i * BATCH_SIZE: i * BATCH_SIZE + BATCH_SIZE], BATCH_SIZE, max_len=MAX_LENGTH)\n",
    "        batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "\n",
    "        logp_seq = rnn_loop(char_rnn, batch_ix)\n",
    "\n",
    "        # compute loss\n",
    "        predictions_logp = logp_seq[:, :-1]\n",
    "        actual_next_tokens = batch_ix[:, 1:]\n",
    "        loss = criterion(predictions_logp.contiguous().view(-1, num_tokens), \n",
    "                      actual_next_tokens.contiguous().view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        train_history.append(loss.data.numpy())\n",
    "        if (i+1)%5==0:\n",
    "            clear_output(True)\n",
    "            plt.plot(train_history,label='loss')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "    if np.mean(train_history) < best_valid_loss:\n",
    "        best_valid_loss = np.mean(train_history)\n",
    "        torch.save(char_rnn.state_dict(), './char_rnn_1.pt')\n",
    "        \n",
    "    history.append(train_history)\n",
    "    writer.add_scalar('mean train loss per epoch', np.mean(train_history), global_step=epoch)\n",
    "    char_rnn.eval()\n",
    "    writer.add_text('generation example',\n",
    "                    generate_sample(char_rnn=char_rnn, seed_phrase=\"мой дядя самых честных правил\", max_length=512, temperature=0.2), \n",
    "                    global_step=epoch)\n",
    "    writer.close()\n",
    "#     print(generate_sample(char_rnn=char_rnn, seed_phrase=\"мой дядя самых честных правил\", max_length=512, temperature=0.2))\n",
    "#     print(f\"epoch {epoch + 1} mean loss: {np.mean(history)}\")\n",
    "#     scheduler.step()\n",
    "#     assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More poetic model\n",
    "\n",
    "Let's use LSTM instead of vanilla RNN and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss function of the number of epochs. Does the final loss become better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNNLoop(nn.Module):\n",
    "    def __init__(self, num_tokens=num_tokens, emb_size=16, rnn_num_units=64, dropout=0.2, num_layers=1):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.lstm_size = rnn_num_units\n",
    "        self.num_layers = num_layers\n",
    "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
    "        self.rnn = nn.LSTM(emb_size, rnn_num_units, batch_first=True, num_layers=num_layers, dropout=dropout)\n",
    "        self.hid_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x, h, c):\n",
    "        assert isinstance(x.data, torch.LongTensor)\n",
    "        h_seq, hn_cn = self.rnn(self.emb(x), (h, c))\n",
    "        next_logits = self.hid_to_logits(h_seq)\n",
    "        next_logp = F.log_softmax(next_logits, dim=-1)\n",
    "        return next_logp, hn_cn\n",
    "    \n",
    "    def initial_state(self, batch_size):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.lstm_size),\n",
    "                torch.zeros(self.num_layers, batch_size, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_LR = 1e-2\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "EMBEDDING_SIZE = 64\n",
    "HIDDEN_SIZE = 128\n",
    "DROPOUT = 0\n",
    "NUM_LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharRNNLoop(\n",
       "  (emb): Embedding(106, 64)\n",
       "  (rnn): LSTM(64, 128, batch_first=True)\n",
       "  (hid_to_logits): Linear(in_features=128, out_features=106, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_lstm = CharRNNLoop(num_tokens=num_tokens, emb_size=EMBEDDING_SIZE, rnn_num_units=HIDDEN_SIZE, num_layers=NUM_LAYERS, dropout=DROPOUT)\n",
    "char_lstm.load_state_dict(torch.load(\"./char_lstm_1.pt\"))\n",
    "char_lstm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_lstm = CharRNNLoop(num_tokens=num_tokens, emb_size=EMBEDDING_SIZE, rnn_num_units=HIDDEN_SIZE, num_layers=NUM_LAYERS, dropout=DROPOUT)\n",
    "opt = torch.optim.Adam(char_lstm.parameters(), lr=BASE_LR)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_writer = SummaryWriter()\n",
    "lstm_writer.add_graph(char_lstm, to_matrix(text[0: BATCH_SIZE], BATCH_SIZE, max_len=MAX_LENGTH))\n",
    "lstm_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_lstm(char_lstm, seed_phrase=' ', max_length=MAX_LENGTH, temperature=1.0):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
    "                        smaller temperature converges to the single most likely output\n",
    "    '''\n",
    "    char_lstm.eval()\n",
    "    h_0, c_0 = char_lstm.initial_state(1)\n",
    "\n",
    "    x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
    "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n",
    "\n",
    "    \n",
    "    #feed the seed phrase, if any\n",
    "    logp_next, hn_cn = char_lstm(x_sequence, h_0, c_0)\n",
    "    p_next = F.softmax(logp_next[0, -1, :] / temperature, dim=0).data.numpy()\n",
    "    next_ix = np.random.choice(num_tokens,p=p_next)\n",
    "    next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
    "    chars = [next_ix]\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        logp_next, hn_cn = char_lstm(chars[-1], *hn_cn)\n",
    "        p_next = F.softmax(logp_next / temperature, dim=-1).data.numpy()[0][0]\n",
    "        \n",
    "        # sample next token and push it back into x_sequence\n",
    "        next_ix = np.random.choice(num_tokens,p=p_next)\n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
    "        chars.append(next_ix)\n",
    "        \n",
    "    return seed_phrase + ''.join([tokens[ix.data.numpy()[0][0]] for ix in chars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5880"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(text) // BATCH_SIZE + 1) * EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = []\n",
    "best_valid_loss = float('inf')\n",
    "for epoch in range(EPOCHS):\n",
    "    train_history = []\n",
    "    char_lstm.train()\n",
    "    for i in range(len(text) // BATCH_SIZE + 1):\n",
    "        batch_ix = to_matrix(text[i * BATCH_SIZE: i * BATCH_SIZE + BATCH_SIZE], BATCH_SIZE, max_len=MAX_LENGTH)\n",
    "        batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "\n",
    "        h_0, c_0 = char_lstm.initial_state(BATCH_SIZE)\n",
    "        logp_seq, hn_cn = char_lstm(batch_ix, h_0, c_0)\n",
    "\n",
    "        # compute loss\n",
    "        predictions_logp = logp_seq[:, :-1]\n",
    "        actual_next_tokens = batch_ix[:, 1:]\n",
    "        loss = criterion(predictions_logp.contiguous().view(-1, num_tokens), \n",
    "                      actual_next_tokens.contiguous().view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        train_history.append(loss.data.numpy())\n",
    "        if (i+1)%5==0:\n",
    "            clear_output(True)\n",
    "            plt.plot(train_history,label='loss')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "    if np.mean(train_history) < best_valid_loss:\n",
    "        best_valid_loss = np.mean(train_history)\n",
    "        torch.save(char_lstm.state_dict(), f'./char_lstm_1_EMBD{EMBEDDING_SIZE}_BATCH{BATCH_SIZE}_HID{HIDDEN_SIZE}.pt')\n",
    "        \n",
    "    history.append(train_history)\n",
    "    lstm_writer.add_scalar('mean train loss per epoch', np.mean(train_history), global_step=epoch)\n",
    "    lstm_writer.add_text('generation example',\n",
    "                    generate_sample_lstm(char_lstm=char_lstm, seed_phrase=\"мой дядя самых честных правил\", max_length=512, temperature=0.2), \n",
    "                    global_step=epoch)\n",
    "    lstm_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate text using the trained net with different `temperature` parameter: `[0.1, 0.2, 0.5, 1.0, 2.0]`.\n",
    "\n",
    "Evaluate the results visually, try to interpret them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharRNNCell(\n",
       "  (embedding): Embedding(106, 64)\n",
       "  (rnn_update): Linear(in_features=192, out_features=128, bias=True)\n",
       "  (rnn_to_logits): Linear(in_features=128, out_features=106, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_char_rnn = CharRNNCell(num_tokens=num_tokens, embedding_size=64, rnn_num_units=128)\n",
    "best_char_rnn.load_state_dict(torch.load(\"./char_rnn_1.pt\"))\n",
    "best_char_rnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN:\n",
      "temperature: 0.1\n",
      "мой дядя в темноте не страшно на мне под подошвы дальной странный делать за стать в темноте всё был с подожденной под подошвы дальной странный века не скажется в темноте всё был и странный как города (почему?) хе-путину мой как будто полно на мне под подошвы дальной странный красивый собой половать делать за стать в том под подошвы дальной странный как гром (эйби)\n",
      "так подруг на балковали на мне под подошвы дальной странный красивый сердце под мог не полете в темноте всё гости с похоток (грустные танцы)\n",
      "я не\n",
      "\n",
      "temperature: 0.2\n",
      "мой дядя в моей стал (ха-ха)\n",
      "я и думал в моей черепит на стреляю своей не дайти (сук, пока под подошвы далью душах под подоры, на под подошвой\n",
      "пора под подоры, старавил бы в как будто половек в руке себе не подождёным на себя в самом домит и все не породительный колет и думать\n",
      "и в семья места\n",
      "я не встафетской доми доми на собой, но ты подруг и мой бетлон (ага)\n",
      "так скупка на мне полно просто в самом колим он под подошвы дальной строй — мне не смерте в старины столом под подошвы дальной строй — мой просто теб\n",
      "\n",
      "temperature: 0.5\n",
      "мой дядя — тебя в мамановцу, и в алыбыл твою тёлку, я старая после домеци его не уж с похорок авте под подыми в от после настои блестит на ходет невозвала двор со мной благоразу с вижу в темноте всё красных грата, в сети (е!)\n",
      "как я поэт себе он своих дуре\n",
      "на подожденной дерьмо так полно ба баш — фрему на меня в темноте так гуди тостьенс милость (грр-ра)                                                                                                                                                             \n",
      "\n",
      "temperature: 1.0\n",
      "мой дядя — умала на свет; и только наш (ахру-м)\n",
      "halke treal)\n",
      "прежни сне черновся раздно брориком разули (ясин)\n",
      "яв внуwбкого себя ваш дришней\n",
      "и нас госкулся свой карят мне не триненность за сиять,\n",
      "и диса\n",
      "я пож но мы рэперас я хокам и дых:\n",
      "я сердать, снова светно\n",
      "уже сыплях,\n",
      "– что двинтом нбуде толкаться оботаться, когда выходо откобы гирде\n",
      "он, пеще ей где мне сукствянский себе умер и дом-ли с обжияли заказвазит, что влегпешь я то же так гняли \"loina shalumuba) и он отдавирги\n",
      "с тупы инталив третилно\n",
      "пацанамяе\n",
      "\n",
      "temperature: 2.0\n",
      "мой дядя хоуз-яйишьы\n",
      "но тустнуед…\n",
      "бабрю вдыщик минкимчта\n",
      "tu, shol'» -p, uw!) ха-тайпт.-ос з mealill\n",
      "по-рабы;\n",
      "ем?                      a al's-ykgct'и цигры! гивираю,\n",
      "элкачашков, шубрый\n",
      "здны\n",
      "жие.\n",
      "это… bea€         l’ice-waye (бню) у… гряетка, бывы впей? сдпое доллбпра!)                                                                                                                                                                                                     а, улинымо, наняещ ненелбию сирась, дж)\n",
      "мужный \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"RNN:\")\n",
    "for temp in [0.1, 0.2, 0.5, 1., 2.]:\n",
    "    print(f\"temperature: {temp}\")\n",
    "    print(generate_sample(char_rnn=best_char_rnn, seed_phrase=\"мой дядя \", max_length=512, temperature=temp) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharRNNLoop(\n",
       "  (emb): Embedding(106, 64)\n",
       "  (rnn): LSTM(64, 128, batch_first=True)\n",
       "  (hid_to_logits): Linear(in_features=128, out_features=106, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_char_lstm = CharRNNLoop(num_tokens=num_tokens, emb_size=EMBEDDING_SIZE, rnn_num_units=HIDDEN_SIZE, num_layers=NUM_LAYERS, dropout=DROPOUT)\n",
    "best_char_lstm.load_state_dict(torch.load(\"./char_lstm_1.pt\"))\n",
    "best_char_lstm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM:\n",
      "temperature: 0.1\n",
      "мой дядя в моей музыкой красивой\n",
      "в сердце не в комнате, чем темнотах на мои был не старины\n",
      "в тишине, если с тобой должно не надо след\n",
      "когда грустно по небо не старин\n",
      "и полно под кругу под миним должно\n",
      "я вижу и только со мной — это мне не старин\n",
      "поле совсем не про нас нет, а я не выходим был обезорые кругом\n",
      "старина ты половей\n",
      "с тобой бедной реденный города и под каконе\n",
      "на груди, на запястье, на груди, на запястье\n",
      "тут страстей своей странной\n",
      "в темноте не старик ль в темноте, не видит подошвой\n",
      "под кровью под кр\n",
      "\n",
      "temperature: 0.2\n",
      "мой дядя в сети\n",
      "что ты будешь делать с этим? (сети-сети-сети-сети)                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      "\n",
      "temperature: 0.5\n",
      "мой дядя мне стал\n",
      "сам мелисочная души и в ней не надо держонах\n",
      "еще половен как будто далекого помнимают\n",
      "отворота, а даже в очерь нет, и моя нам\n",
      "все радость на компой богате\n",
      "пора потом большода своей.\n",
      "                                                                                                                                                                                                                                                                                                                         \n",
      "\n",
      "temperature: 1.0\n",
      "мой дядя о это фрэг-ты\n",
      "сколько оленький так — чик.\n",
      "красный накеде я блибли нет?\n",
      "она на баллись так каждётся поэта\n",
      "без волше зналька,\n",
      "глядь пежал и мне сбир,\n",
      "она даже чири во всё как ты, эй, это ли пидор,\n",
      "в он твои девую и яхниг.\n",
      "                                                                                                                                                                                                                                                                                            \n",
      "\n",
      "temperature: 2.0\n",
      "мой дядя дволи читариках\n",
      "няжог\n",
      "уверадайся матычие h-илокл – садей\n",
      "дииверчат мечтоя 40:\n",
      "текених школюктучию нас тас\n",
      "вальск и пять лыжут ми\n",
      "я рад blel d\n",
      "лудтый, нагрешное мажем.\n",
      "теперь уведусих никто все…\n",
      "эбишк ребюучный без чащношноя, а\n",
      "фраснул вечна извласнюсу;\n",
      "добулсынек\n",
      "рязоз поограз-кас, а бошка.\n",
      "идрай софф яя!..                                                                                                                                                                                                    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"LSTM:\")\n",
    "for temp in [0.1, 0.2, 0.5, 1., 2.]:\n",
    "    print(f\"temperature: {temp}\")\n",
    "    print(generate_sample_lstm(char_lstm=best_char_lstm, seed_phrase=\"мой дядя \", max_length=512, temperature=temp) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "1. <a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness/'> Andrew Karpathy blog post about RNN. </a> \n",
    "There are several examples of genration: Shakespeare texts, Latex formulas, Linux Sourse Code and children names.\n",
    "2. <a href='https://github.com/karpathy/char-rnn'> Repo with char-rnn code </a>\n",
    "3. Cool repo with PyTorch examples: [link](https://github.com/spro/practical-pytorch`)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
